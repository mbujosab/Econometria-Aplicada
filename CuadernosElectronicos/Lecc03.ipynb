{"cells":[{"cell_type":"markdown","id":"5e9ba632-146d-486f-b90d-e57dafcf2eee","metadata":{},"source":"Lección 3. Modelos lineales\n===========================\n\n**Author:** Marcos Bujosa\n\n"},{"cell_type":"markdown","id":"1b819c80-9676-4558-b866-3170b2e8f5cd","metadata":{},"source":["<div class=\"abstract\" id=\"orgdb775f1\">\n<p>\nAnalizaremos las dificultades que plantea la <b>correlación serial</b> y veremos cómo la estacionariedad en sentido débil las simplifica. \nLos modelos de procesos estacionarios son útiles para representar la dependencia de los valores de una serie temporal respecto de su pasado.\nNos centraremos en los <b>procesos lineales</b>, estudiando su valor esperado, su función de autocovarianza y las covarianzas cruzadas entre ellos.  \n</p>\n\n</div>\n\n-   ([slides](https://mbujosab.github.io/Econometria-Aplicada/Transparencias/Lecc03.slides.html)) &mdash; ([html](https://mbujosab.github.io/Econometria-Aplicada/Lecciones-html/Lecc03.html)) &mdash; ([pdf](https://mbujosab.github.io/Econometria-Aplicada/Lecciones-pdf/Lecc03.pdf)) &mdash; ([mybinder](https://mybinder.org/v2/gh/mbujosab/Econometria-Aplicada/gh-pages?labpath=CuadernosElectronicos/Lecc03.ipynb))\n\n"]},{"cell_type":"markdown","id":"7ca013cd-b105-4c5d-acf7-6de87a5098d5","metadata":{"slideshow":{"slide_type":"skip"}},"source":["#### Carga de algunos módulos de python y creación de directorios auxiliares\n\n"]},{"cell_type":"code","execution_count":1,"id":"8459993d-31ec-4a0b-bb91-297a8b8f061b","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["# Para trabajar con los datos y dibujarlos necesitamos cargar algunos módulos de python\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib as mpl\n# definimos parámetros para mejorar los gráficos\nmpl.rc('text', usetex=False)\nimport matplotlib.pyplot as plt   # data visualization"]},{"cell_type":"markdown","id":"2e09ba6d-591a-4344-a3b5-5ac2defebd24","metadata":{"slideshow":{"slide_type":"skip"}},"source":["##### Creación del directorio auxiliar para albergar las figuras de la lección\n\n"]},{"cell_type":"markdown","id":"8fb7306a-e4c2-4dfe-95de-a7b4948702fd","metadata":{"slideshow":{"slide_type":"skip"}},"source":["Para publicar la lección como pdf o página web, necesito los gráficos como ficheros `.png` alojados algún directorio específico:\n\n"]},{"cell_type":"code","execution_count":1,"id":"ef80fe67-796c-4d10-8d4e-d74db998c293","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["imagenes_leccion = \"./img/lecc03\" # directorio para las imágenes de la lección\nimport os\nos.makedirs(imagenes_leccion, exist_ok=True) # crea el directorio si no existe"]},{"cell_type":"markdown","id":"e24bd717-bc45-4125-b988-65f17075a720","metadata":{"slideshow":{"slide_type":"skip"}},"source":["Con el siguiente código mejoro los gráficos y logro transformar las tablas con formato $\\LaTeX{}$ en ficheros png.\n\n"]},{"cell_type":"code","execution_count":1,"id":"2452b124-fa05-4f67-86f5-ac600e587127","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["# definimos parámetros para mejorar los gráficos\nmpl.rc('text', usetex=True)\nmpl.rc('text.latex', preamble=r'\\usepackage{amsmath}')\n\n# transformaré salidas en \\LaTeX{} de statsmodels a ficheros png que incluiré en las transparencias\nimport dataframe_image as dfi\nfrom sympy.printing.preview import preview\ndef repr_png(tex, ImgFile):\n    preamble = \"\\\\documentclass[preview]{standalone}\\n\" \\\n        \"\\\\usepackage{booktabs,amsmath,amsfonts}\\\\begin{document}\"    \n    preview(tex, filename=ImgFile, viewer='file', preamble=preamble, dvioptions=['-D','250'])"]},{"cell_type":"markdown","id":"f98b10ab-399c-43a6-9d86-e788c469bde6","metadata":{"slideshow":{"slide_type":"slide"}},"source":["## Series temporales vs datos de sección cruzada\n\n"]},{"cell_type":"markdown","id":"64846f86-85ee-42a4-9d32-7ee3f5d0c055","metadata":{},"source":["Corresponden a observaciones de un mismo objeto a lo largo del\ntiempo. El índice indica el instante de cada medición. *El orden\ncronológico puede ser crucial* al modelar los datos.\n\n-   El motivo es que frecuentemente el valor medido en un instante de\n    tiempo está relacionado con otras mediciones próximas en el tiempo\n    (*correlación serial*).\n\n-   Si es así, ya no deberíamos asumir que las variables aleatorias del\n    proceso estocástico subyacente, $\\boldsymbol{X}=(X_t\\mid\n      t\\in\\mathbb{Z})$, son independientes entre sí.\n\nEsto tiene importantes implicaciones en las técnicas de análisis y\nlos modelos a utilizar.\n\n"]},{"cell_type":"markdown","id":"b9833fbd-8e91-42eb-b341-df79a84ed17d","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["1.  Las series temporales se clasifican en **estacionarias** y **no estacionarias.**\n2.  Las series temporales estacionarias no muestran tendencias a largo plazo o volatilidad cambiante.\n3.  Las no estacionarias presentan tendencia, estacionalidad o volatilidad cambiante.\n4.  La clasificación de series **depende del periodo de observación.**\n5.  **Esta clasificación de las series temporales no es rigurosa (se ha tomado prestada de los procesos estocásticos).**\n\n"]},{"cell_type":"markdown","id":"1e94f9ce-4964-489b-b1bd-a6fe851a7d62","metadata":{"slideshow":{"slide_type":"notes"}},"source":["1.  Las series temporales se suelen clasificar en dos categorías principales: \\`\\`estacionarias'' y \\`\\`no estacionarias''. Las series estacionarias son aquellas que mantienen un nivel constante a lo largo del tiempo, sin mostrar tendencias ascendentes o descendentes. En contraste, las series no estacionarias presentan cambios significativos a lo largo del tiempo, incluyendo tendencias, estacionalidad o volatilidad cambiante. Es fundamental identificar la naturaleza de la serie temporal para aplicar métodos de análisis adecuados, ya que cada tipo requiere enfoques y técnicas diferentes.\n\n2.  Una serie temporal estacionaria se caracteriza por la estabilidad de sus valores en el tiempo, lo que significa que las fluctuaciones alrededor de un valor medio no alteran el comportamiento general del fenómeno observado. Ejemplos de fenómenos \\`\\`estacionarios'' pueden incluir la cantidad de lluvia que cae en una región particular cada año o la temperatura promedio. A menudo, estos procesos son más fáciles de modelar y predecir, dado que sus propiedades estadísticas no cambian con el tiempo.\n\n3.  A diferencia de las series temporales estacionarias, las no estacionarias exhiben características más complejas que pueden incluir tendencias a largo plazo, ciclos estacionales, patrones evolutivos y volatilidad cambiante. Esto significa que las variables pueden crecer o decrecer de manera continua, como es evidente en las series de renta nacional o en las ventas de una empresa. El estudio de estas dinámicas es esencial para entender contextos económicos, sociales y climáticos, permitiendo a los analistas hacer pronósticos más informados.\n\n4.  El comportamiento de las series temporales puede variar dependiendo del intervalo de tiempo considerado para su análisis. Una serie puede parecer estacionaria en un periodo corto, pero al extender el periodo de observación, se pueden revelar tendencias no evidentes en un principio.\n\n5.  Es decir, los términos \\`\\`estacionario'' y \\`\\`no estacionario'' aplicados a las series temporales son coloquiales (no hay un rigor matemático detrás del término). Aplicados a una serie temporal, comunican que, por su apariencia, podría suponerse que son una realización de un proceso estocástico \\`\\`estacionario'' o \\`\\`no estacionario'' (aplicados a procesos estocásticos, estos términos sí tienen una definición precisa y rigurosa).\n\n"]},{"cell_type":"markdown","id":"f6d63e59-a791-4a38-b8d3-09aee38e02ed","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["Veamos algunos ejemplos de series temporales&hellip;\n\n"]},{"cell_type":"code","execution_count":1,"id":"b1c76f6d-b7d4-4d84-b472-df3faaa3b41e","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["path = '../datos/'\ndf1 = pd.read_csv(path+'PoblacionAustralia.csv')\ndf2 = pd.read_csv(path+'PIB_UEM.csv')\ndf3 = pd.read_csv(path+'Retiro.txt')\ndf4 = pd.read_csv(path+'IBEX35.csv')\ndf5 = pd.read_csv(path+'ProduccionCemento.csv')"]},{"cell_type":"markdown","id":"aa0b8b1e-8a4c-4fa2-903e-6fd98f027fe4","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["##### Población en Australia\n\n"]},{"cell_type":"code","execution_count":1,"id":"38c318bf-3af2-4707-b3df-5e422c2b9b9b","metadata":{"slideshow":{"slide_type":"notes"}},"outputs":[],"source":["df1.plot(x='obs',xlabel='Años',ylabel='Habitantes',figsize=(15,4)).set_title('Población australiana (datos anuales)',fontsize=18)\nplt.savefig('./img/lecc03/PoblacionAustralia.png', dpi=300, bbox_inches='tight')"]},{"cell_type":"markdown","id":"d3fed118-5001-416c-8c7e-ea985f0154d4","metadata":{},"source":["![img](./img/lecc03/PoblacionAustralia.png)\n\n"]},{"cell_type":"markdown","id":"c1b1dc62-8b3e-4416-8e66-c41a645742de","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["##### PIB UEM\n\n"]},{"cell_type":"code","execution_count":1,"id":"fd7bfc5e-949d-4006-9e35-e6ef27409bfc","metadata":{"slideshow":{"slide_type":"notes"}},"outputs":[],"source":["# Crear el gráfico\nfig, ax = plt.subplots(figsize=(15, 5))\ndf2.plot(x='obs', xlabel='Trimestres', ylabel='Miles de millones de euros', ax=ax)\nax.set_title('PIB UEM a precios corrientes (datos trimestrales). Fuente Banco de España', fontsize=18)\n\n# Agregar líneas verticales con diferente grosor\nfor i, obs in enumerate(df2['obs']):\n    if obs.endswith('Q1'):  # Primer trimestre\n        ax.axvline(x=i, color='gray', linestyle='--', linewidth=1.5)  # Más gruesa\n    else:  # Otros trimestres\n        ax.axvline(x=i, color='gray', linestyle='--', linewidth=0.5)  # Más fina\n\n# Personalizar las etiquetas del eje X\nticks = []\nlabels = []\nfor i, obs in enumerate(df2['obs']):\n    if obs.endswith('Q1'):  # Etiquetas solo en los primeros trimestres\n        ticks.append(i)  # Usar el índice como posición\n        labels.append(obs)\n\nax.set_xticks(ticks)  # Configurar las posiciones de las etiquetas\nax.set_xticklabels(labels, rotation=45)  # Configurar las etiquetas correspondientes\n\n# Asegurar que todas las líneas y etiquetas se muestren\nplt.tight_layout()\nplt.savefig('./img/lecc03/PIB_UEM.png', dpi=300, bbox_inches='tight')"]},{"cell_type":"markdown","id":"ab657285-d687-40a3-8ddd-7ca8c3c12a07","metadata":{},"source":["![img](./img/lecc03/PIB_UEM.png)\n\n"]},{"cell_type":"markdown","id":"2cf6ee67-997f-4876-8afb-fb7ad5afaa98","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["##### Temperatura media en el Parque del Retiro. Madrid\n\n"]},{"cell_type":"code","execution_count":1,"id":"6bb84bff-9121-440c-967c-41822a310d51","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["# Generar una columna de fechas desde enero de 1985\ndf3['Fecha'] = pd.date_range(start='1985-01', periods=len(df3), freq='M') # cambiar por 'ME' en el futuro\n\n# Configurar la columna de fechas como índice\ndf3.set_index('Fecha', inplace=True)\n\n# Crear el gráfico\nfig, ax = plt.subplots(figsize=(15, 5))\nax.plot(df3.index, df3['TemperaturaMedia'], label='Temperatura Media Mensual')\nax.set_title('Temperatura media mensual en el Parque del Retiro. Fuente: Comunidad de Madrid', fontsize=18)\nax.set_xlabel('Meses')\nax.set_ylabel('Temperatura Media')\nax.legend()\n\n# Agregar barras verticales en enero de cada año\nfor fecha in df3.index:\n    if fecha.month == 1:  # Mes de enero\n        ax.axvline(x=fecha, color='gray', linestyle='--', linewidth=0.8)\n\n# Agregar etiquetas en todos los eneros\nticks = []\nlabels = []\nfor fecha in df3.index:\n    if fecha.month == 1:  # Enero\n        ticks.append(fecha)\n        labels.append(f'Ene {fecha.year}')  # Formato: \"Ene Año\" (ej. \"Ene 1985\")\n\nax.set_xticks(ticks)  # Configurar las posiciones de las etiquetas\nax.set_xticklabels(labels, rotation=45)  # Configurar las etiquetas correspondientes\n\n# Asegurar que todas las líneas y etiquetas se muestren\nplt.tight_layout()\n# Guardar el gráfico\nplt.savefig('./img/lecc03/TemperaturaRetiro.png', dpi=300, bbox_inches='tight')"]},{"cell_type":"markdown","id":"3a821ffb-e06e-4b16-b1a4-3dc112150500","metadata":{},"source":["![img](./img/lecc03/TemperaturaRetiro.png)\n\n"]},{"cell_type":"markdown","id":"c77c417d-6f75-4851-9616-771a25c6395b","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["##### Rendimiento porcentual diario del IBEX 35 (std)\n\n"]},{"cell_type":"code","execution_count":1,"id":"57dc38d8-0109-4ec2-bf2f-0f76acf86a6d","metadata":{"slideshow":{"slide_type":"notes"}},"outputs":[],"source":["df4.plot(x='obs',xlabel='Días',ylabel='Desviaciones típicas',figsize=(15,4)).set_title('Rendimiento porcentual diario del IBEX 35 (std.). Fuente: Archivo Prof. Miguel Jerez',fontsize=18)\nplt.savefig('./img/lecc03/IBEX35.png', dpi=300, bbox_inches='tight')"]},{"cell_type":"markdown","id":"f8b2e817-eb59-4c8f-941b-884e03bddd84","metadata":{},"source":["![img](./img/lecc03/IBEX35.png)\n\n"]},{"cell_type":"markdown","id":"19a7248b-be9f-4b93-b784-84a417ffc92e","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["##### Producción de cemento\n\n"]},{"cell_type":"code","execution_count":1,"id":"2fcca23f-8e4e-4c59-84b6-e67d61a5b000","metadata":{"slideshow":{"slide_type":"notes"}},"outputs":[],"source":["fig, ax = plt.subplots(figsize=(15, 5))\ndf5.plot(x='obs', xlabel='Meses', ylabel='Miles de Toneladas métricas', ax=ax)\nax.set_title('Producción de cemento (Datos mensuales). Fuente Banco de España', fontsize=18)\n\n# Agregar líneas verticales con diferente grosor para años pares e impares\nfor i, obs in enumerate(df5['obs']):\n    if obs.endswith('M01'):  # Enero\n        year = int(obs.split('M')[0])  # Extraer el año\n        if year % 2 == 0:  # Años pares\n            ax.axvline(x=i, color='gray', linestyle='--', linewidth=1.5)  # Más gruesa\n        else:  # Años impares\n            ax.axvline(x=i, color='gray', linestyle='--', linewidth=0.8)  # Más fina\n\n# Personalizar las etiquetas del eje X para eneros de años pares\nticks = []\nlabels = []\nfor i, obs in enumerate(df5['obs']):\n    if obs.endswith('M01'):  # Enero\n        year = int(obs.split('M')[0])  # Extraer el año\n        if year % 2 == 0:  # Solo años pares\n            ticks.append(i)  # Usar el índice como posición\n            labels.append(obs)  # Etiqueta completa (ej. \"1986M01\")\n\nax.set_xticks(ticks)  # Configurar las posiciones de las etiquetas\nax.set_xticklabels(labels, rotation=45)  # Configurar las etiquetas correspondientes\n\n# Asegurar que todas las líneas y etiquetas se muestren\nplt.tight_layout()\nplt.savefig('./img/lecc03/ProduccionCemento.png', dpi=300, bbox_inches='tight')"]},{"cell_type":"markdown","id":"68563858-b5fa-4d25-a8c8-4464bc1574bd","metadata":{},"source":["![img](./img/lecc03/ProduccionCemento.png)\n\n"]},{"cell_type":"markdown","id":"4dd34f20-3780-4ace-a4d9-bd16c59016c4","metadata":{"slideshow":{"slide_type":"notes"}},"source":["Las anteriores series temporales presentan características que impiden su consideración como realizaciones de procesos estocásticos estacionarios. \n\n-   En tres de ellas &mdash;la población en Australia, el PIB de la zona euro y la producción de cemento&mdash; se observa una tendencia clara, lo que implica una evolución de la media local a medio y largo plazo.\n-   Además, se identifican patrones estacionales en las temperaturas medias del Parque del Retiro y en la producción de cemento. Estos patrones son el resultado de la **traslación constante de la Tierra** alrededor del Sol. Tales oscilaciones periódicas generan ciclos regulares, de manera que, por ejemplo, las temperaturas invernales son sistemáticamente más bajas que las estivales.\n-   En la producción de cemento, se observa que la amplitud de la variación estacional tiende a aumentar conforme se incrementa el nivel de la serie.\n-   Respecto a los rendimientos del IBEX35, se aprecian períodos de alta volatilidad intercalados con fases menos volátiles, lo que indica la presencia de heterocedasticidad.\n\nTodas estas características resaltan la complejidad de los procesos subyacentes y la necesidad de emplear modelos que capten adecuadamente estas propiedades dinámicas.\n\n"]},{"cell_type":"markdown","id":"fe82fa70-ce9b-429d-93e4-29cd1e5e1ca7","metadata":{"slideshow":{"slide_type":"slide"}},"source":["### Correlación serial vs muestreo aleatorio simple\n\n"]},{"cell_type":"markdown","id":"39bcc6d0-eb3b-48f8-9a41-d25f3a2f5891","metadata":{},"source":["*Generalmente* cuando disponemos de datos de\n\n-   **sección cruzada:** asumimos que proceden de un el muestreo es aleatorio simple\n    -   i.e., los datos son realizaciones de variables aleatorias i.i.d.\n\n-   **series temporales:** dicha asunción suele ser errónea\n    \n    -   con frecuencia el nivel esperado (o la volatilidad) parece cambiar con $t$\n    -   con frecuencia hay dependencia temporal (correlación serial).\n    \n    **Ejemplo**: no parece aceptable asumir que $ProdCemento_{1960M01}$ se distribuye igual que $ProdCemento_{2000M04}$ (ni que sea independiente de $ProdCemento_{1959M01}$).\n\nVeamos por qué esto genera dificultades en su tratamiento estadístico&hellip;\n\n"]},{"cell_type":"markdown","id":"db196575-5504-4a27-bf97-00efa5a348d6","metadata":{"slideshow":{"slide_type":"skip"}},"source":["Un proceso estocástico $\\boldsymbol{X}$ es un conjunto de variables aleatorias $X_t$ donde el índice $t$ toma valores en un cierto conjunto $C$. En nuestro caso, este conjunto es el conjunto de los números enteros $\\mathbb{Z}$.\n\nEl proceso $\\boldsymbol{X}$ queda caracterizado si definimos la distribución de probabilidad conjunta de cualquier subconjunto finito de variables aleatorias $(X_p, \\ldots, X_k, \\ldots, X_q)$. Estas distribuciones se denominan distribuciones finito-dimensionales del proceso. Diremos que conocemos la estructura probabilística de un proceso estocástico cuando conocemos la distribución de cualquier subconjunto de variables; en particular, también las distribuciones marginales de cada variable.\n\n"]},{"cell_type":"markdown","id":"102e90f4-f7a3-496f-8291-590f425b242e","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["Consideremos el proceso estocástico\n$$\n \\boldsymbol{X}=(X_t \\mid t=0,\\pm1,\\pm2,\\ldots).\n$$\nCaracterizar su distribución conjunta (**sus infinitos momentos**) resulta ser demasiado ambicioso. Limitemos a la esperanza para cada $t$ y covarianza de cada par $(t,k)$:\n\n$$\n E(X_t)=\\mu_{\\color{Blue}{t}}\n \\quad\\text{ y }\\quad\n Cov(X_t,X_k)=E\\big[(X_t-\\mu_t)(X_k-\\mu_k)\\big]=\\gamma_{{\\color{Blue}{t}},{\\color{OliveGreen}{k}}};\\quad t,k\\in\\mathbb{Z}\n$$\n\n(donde si $\\;k=t\\;$, entonces $\\;\\gamma_{\\color{Blue}{{t,t}}}=Var(X_t)=\\sigma^2_{\\color{Blue}{t}}$).\n\n"]},{"cell_type":"markdown","id":"239a905c-e431-4f09-8af2-de809a01e8c0","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["Si el proceso $\\boldsymbol{X}$ fuera gaussiano, estos parámetros bastarían para caracterizar la distribución conjunta completamente. No obstante&hellip;\n\n-   Necesitaríamos una muestra suficiente de cada $X_t$ para estimar los parámetros;\n    \n    A cada $X_t$ le corresponden infinitos parámetros: $\\mu_{t}$, $\\;\\sigma^2_{t}$, $\\;\\gamma_{t,{\\color{OliveGreen}{k}}};\\;\\text{ donde } k\\in\\mathbb{Z}$.\n    \n    Pero en una serie temporal $\\boldsymbol{x}$ solo disponemos de *una* realización para cada $X_t$.\n\n"]},{"cell_type":"markdown","id":"0bb5c4c0-065e-490f-bdfd-21226ef3054c","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["### Simplificación del escenario\n\n"]},{"cell_type":"markdown","id":"d479f66c-dd7b-4593-93e2-02f564d8e9eb","metadata":{},"source":["Cuando $\\boldsymbol{X}$ es [débilmente estacionario](./Lecc01.slides.html#/3/1) se reduce *drásticamente* el número de parámetros (aunque siga habiendo infinitos):\n\n\\begin{eqnarray}\n  E(X_t)  = &  \\mu \\\\\n  Cov(X_t,X_{t-k}) =  & \\gamma_k\\quad k\\in\\mathbb{Z}\n\\end{eqnarray}\n\n"]},{"cell_type":"markdown","id":"20cd1591-b894-4915-a29f-12d9271a0e9b","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["El desafío para el analista es (y nótese el abuso de lenguaje)\n\n-   **primero:** transformar los datos para lograr que sean \"***débilmente estacionarios***\".\n    -   (Algo vimos en la lección 1)\n-   **después:** transformar los datos estacionarios en \"***ruido blanco***\"\n    -   (Es lo que veremos en esta lección y las siguientes)\n\nEste proceso constituye la especificación y ajuste de un modelo ARIMA a los datos.\n\n"]},{"cell_type":"markdown","id":"669e5d22-8279-4f83-bb84-31d44d820b31","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["Antes de atacar los temas de especificación y ajuste de modelos, debemos estudiar las propiedades de la familia de procesos estocásticos débilmente estacionarios.\n\n"]},{"cell_type":"markdown","id":"a311c283-7721-4bbf-b561-6645009e21d9","metadata":{"slideshow":{"slide_type":"skip"}},"source":["## Procesos estocásticos de segundo orden\n\n"]},{"cell_type":"markdown","id":"3e29dced-991c-455b-aa14-729c15cb992a","metadata":{"slideshow":{"slide_type":"skip"}},"source":["El ambiente natural para estudiar las propiedades de segundo orden de\nuna colección de variables aleatorias es el espacio de variables\naleatorias $X$ definidas en un espacio de probabilidad tales que\n$$E(X)=0 \\quad\\text{y}\\quad E(X^2)<\\infty$$ donde $E$ es el operador\nesperanza. Denotaremos este espacio con $H$.\n\n"]},{"cell_type":"markdown","id":"2c05de97-0697-4390-96a6-3c47c2583b38","metadata":{"slideshow":{"slide_type":"skip"}},"source":["### Un poco de geometría\n\n"]},{"cell_type":"markdown","id":"a87e112a-a52b-40dd-922c-7b635eed51ec","metadata":{"slideshow":{"slide_type":"skip"}},"source":["Un espacio vectorial, dotado de producto escalar y norma; por ejemplo $$\\langle X \\mid Y\n\\rangle=E(XY),\\qquad \\lVert X \\rVert= \\sqrt{E(X^2)},\\qquad X,Y \\in\nH,$$ es un espacio de Hilbert.\n\nNótese que como las variables de $H$ tienen esperanza cero, el\nproducto escalar entre $X,Y\\in H$ también es $$\\langle X \\mid Y\n\\rangle=Cov(X,Y).$$ Por tanto, en este espacio $H$ la noción\ngeométrica de ortogonalidad coincide con la noción estadística de *no\ncorrelación*. Por tanto, en este contexto los términos producto\nescalar, covarianza y esperanza del producto serán intercambiables\n(esto deja de ser cierto cuando hay variables aleatorias con esperanza\nno nula).\n\nUna colección de variables aleatorias pertenecientes a $H$ \n$$\\boldsymbol{X}=(X_t\\mid t\\in\\mathbb{Z}) \\;\\text{ con }\\; X_t\\in H$$\nse denomina *proceso estocástico de segundo orden*.\n\nSi $\\boldsymbol{Y}=(Y_t\\mid t\\in\\mathbb{Z})$ es tal que $E(Y_t)=\\mu\\ne0$, entonces $\\boldsymbol{Y}$ no es de segundo orden.\n\nPero basta restar $\\mu$ de cada $Y_t$ para tener un proceso $(\\boldsymbol{Y}-\\mu\\boldsymbol{1})$ de segundo orden.\n\n*Por ello siempre asumiremos* (sin pérdida de generalidad) *que las variables aleatorias de los procesos estocásticos de esta lección* (y la siguiente) *tienen esperanza cero*.\n\nUna propiedad fundamental de los procesos estocásticos estacionarios es que forman un conjunto cerrado bajo combinaciones lineales; es decir, cualquier proceso estocástico obtenido mediante una combinación lineal de procesos estocásticos estacionarios es estacionario. En particular, un proceso estocástico definido por los incrementos de otro proceso estocástico estacionario es estacionario: \n$$X_t=Z_t-Z_{t-1}.$$\n\n"]},{"cell_type":"markdown","id":"b85b4c4c-2bb6-4bcd-abc2-c128cd4aaaa1","metadata":{"slideshow":{"slide_type":"skip"}},"source":["### Primeros momentos de procesos estocásticos de segundo orden\n\n"]},{"cell_type":"markdown","id":"00efd83e-4bbe-422f-99a0-3b9199232a3e","metadata":{"slideshow":{"slide_type":"skip"}},"source":["Si $E(X_t)<\\infty$ para $t\\in\\mathbb{Z}$, entonces $E(\\boldsymbol{X})$ es\nla secuencia $$E(\\boldsymbol{X})=\\big(E(X_t)\\mid\nt\\in\\mathbb{Z}\\big)=\\sum\\nolimits_{t\\in\\mathbb{Z}} E(X_t)\nz^t=\\big(\\ldots,\\;E(X_{-1}),\\;E(X_{0}),\\;E(X_{1}),\\ldots\\big)$$\n\nSi $\\boldsymbol{X}$ tiene segundos momentos finitos, la secuencia de\nautocovarianzas <u>de orden $k$</u> es\n\n\\begin{align*}\n%Cov(\\boldsymbol{X},\\boldsymbol{X}*z^k) = &\n%E\\Big(\\big[\\boldsymbol{X}-E(\\boldsymbol{X})\\big]\\odot\\big[(\\boldsymbol{X}-E(\\boldsymbol{X}))*z^k\\big]\\Big)\\\\\n\\left.\\Big(Cov(X_t,X_{t-k})\\right| t\\in\\mathbb{Z}\\Big)\n= & \n%\\left.\\Big(E\\big[\\big(X_t-E(X_t)\\big)\\big(X_{t-k}-E(X_{t-k})\\big)\\big]\\; \\right| t\\in\\mathbb{Z}\\Big)\\\\\n%=&\n% \\sum_{t\\in\\mathbb{Z}} \\gamma_{_{k,t}} z^t\n(\\gamma_{_{k,t}}\\mid t\\in\\mathbb{Z})\\\\ % \\;=\\;\n= &\n(\\ldots,\\,\\gamma_{_{k,-1}},\\,{\\color{blue}{\\gamma_{_{k,0}}}},\\,\\gamma_{_{k,1}},\\,\\gamma_{_{k,2}},\\ldots).\n\\end{align*}\n\n(la secuencia solo contiene la covarianza de un orden $k$ fijo&hellip; pero en distintos instantes $t$).\n\nAsí, para cada par $(k,t)$, tenemos la covarianza $\\gamma_{k,t}$ entre\n$X_t$ y $X_{t-k}$. Por tanto, en general, tenemos una esperanza para\ncada $t$ y una covarianza de orden $k$ para cada $t$. Dado que $t$\nrecorre todos los números enteros (son muchos momentos). <u>Por\neso necesitamos reducir el número de parámetros restringiéndonos a\nprocesos estocásticos débilmente estacionarios</u>.\n\n"]},{"cell_type":"markdown","id":"7260e163-04d4-44ab-978d-bf0ca3989cc6","metadata":{"slideshow":{"slide_type":"slide"}},"source":["### Procesos estocásticos (débilmente) estacionarios y la ACF\n\n"]},{"cell_type":"markdown","id":"5ada38b9-f006-464d-8d4c-e41d62225ba8","metadata":{},"source":["Un proceso estocástico de segundo orden $\\boldsymbol{X}$ se dice que es *débilmente estacionario* si:\n\n-   $E(X_t)=\\mu$ para todo $t$ y\n-   la covarianza entre $X_s$ y $X_t$ solo depende de la diferencia $s-t$.\n\nEn tal caso, llamamos <u>función de autocovarianzas</u> a la siguiente secuencia:\n$$\n \\boldsymbol{\\gamma} \n \\; = \\; \n (\\gamma_{k}\\mid k\\in\\mathbb{Z}) \n \\; = \\;\n (\\ldots,\\,\\gamma_{-1},\\,{\\color{blue}{\\gamma_{0}}},\\,\\gamma_{1},\\,\\gamma_{2},\\ldots)\n \\;=\\;\n \\sum_{-\\infty}^{\\infty} \\gamma_k z^k.\n$$\n\n**Propiedades** de la función de autocovarianzas $\\boldsymbol{\\gamma}$ (ACF):\n\n-   $\\gamma_0\\geq0$\n-   la secuencia $\\boldsymbol{\\gamma}$ *es definida positiva*; y por tanto,\n    -   $\\boldsymbol{\\gamma}$ es simétrica: $\\gamma_k=\\gamma_{-k}$\n    -   $\\boldsymbol{\\gamma}$ es acotada: $|\\gamma_k|\\leq\\gamma_0$\n\nY llamamos <u>función de autocorrelación</u> (ACF) a la secuencia:\n$\\;\\boldsymbol{\\rho}=\\frac{1}{\\gamma_0}(\\boldsymbol{\\gamma})\n=\\sum\\limits_{k\\in\\mathbb{Z}}\\frac{\\gamma_k}{\\gamma_0}z^k$.\n\n"]},{"cell_type":"markdown","id":"ef1c2d65-d119-40e0-9430-78e956eff2b6","metadata":{"slideshow":{"slide_type":"slide"}},"source":["## Notación: convolución y el operador retardo\n\n"]},{"cell_type":"markdown","id":"8f98007b-5262-4025-a593-245202aa996d","metadata":{},"source":["SI $\\boldsymbol{a}$ es una secuencia de números y $\\boldsymbol{X}$ un proceso estocástico tales que, para todo $t$, \n$$\n \\text{la suma }\\quad  \\sum\\limits_{k=-\\infty}^{\\infty}a_kX_{t-k}\\quad \\text{ converge};\n$$\ndefinimos el producto convolución ($*$) de $\\boldsymbol{a}$ con $\\boldsymbol{X}$ como el proceso estocástico:\n$$\n \\boldsymbol{a}*\\boldsymbol{X}=\\left(\\left.\\sum_{k+s=t} a_k X_s \\right| t\\in\\mathbb{Z}\\right)\n$$\nes decir\n$$\n (\\boldsymbol{a}*\\boldsymbol{X})_t=\\sum_{k+s=t} a_k X_s,\\quad \\text{para } t\\in\\mathbb{Z}.\n$$\nPor tanto, cada elemento de \n$\n (\\boldsymbol{a}*\\boldsymbol{X})\n$\nes una combinación de variables aleatorias de $\\boldsymbol{X}$.\n\n"]},{"cell_type":"markdown","id":"9988b14a-8e6d-46a0-b856-2110a52c6bf7","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["Si aplicamos el operador $\\mathsf{B}$ sobre un elemento de $\\boldsymbol{X}$ obtenemos el anterior:\n$$\n \\mathsf{B} X_t = X_{t−1},\\quad \\text{para } t\\in\\mathbb{Z}.\n$$\nPor tanto, aplicando el operador retardo $\\mathsf{B}$ repetidamente tenemos\n$$\n\\mathsf{B}^k X_t = X_{t−k},\\quad \\text{para } t,z\\in\\mathbb{Z}.\n$$\n\n"]},{"cell_type":"markdown","id":"e306cd8c-1cbc-4e12-98f7-3c635b555f84","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["Así, para el polinomio $\\boldsymbol{a}(z)=a_0+a_1z+a_2z^2+a_3z^3$, y el proceso estocástico $\\boldsymbol{Y}$:\n\n\\begin{align*}\n\\boldsymbol{a}(\\mathsf{B})Y_t \n& = (a_0+a_1\\mathsf{B}+a_2\\mathsf{B}^2+a_3\\mathsf{B}^3) Y_t \\\\\n% & = a_0 Y_t + a_1 \\mathsf{B}^1 Y_t + a_2 \\mathsf{B}^2 Y_t + a_3 \\mathsf{B}^3 Y_t \\\\\n& = a_0Y_t+a_1Y_{t-1}+a_2Y_{t-2}+a_3Y_{t-3} \\\\\n% \\quad = \\quad \\sum\\nolimits_{k=0}^{3}a_kY_{t-k} \\\\\n% & =\\sum\\nolimits_{r=0}^3 a_r Y_{t-r} \\\\\n& =(\\boldsymbol{a}*\\boldsymbol{Y})_t,\\quad \\text{para } t\\in\\mathbb{Z}\n\\end{align*}\n\n"]},{"cell_type":"markdown","id":"eb46d786-1807-4462-b2ca-a8915e83dff8","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["Y en general, si la suma $\\sum\\nolimits_{k=-\\infty}^{\\infty}a_kY_{t-k}$\nconverge para todo $t$, entonces\n\n\\begin{align*}\n\\boldsymbol{a}(\\mathsf{B})Y_t \n& = (\\cdots+a_{-2}\\mathsf{B}^{-2}+a_{-1}\\mathsf{B}^{-1}+a_0+a_1\\mathsf{B}+a_2\\mathsf{B}^2+\\cdots) Y_t \\\\\n% & = a_0 Y_t + a_1 \\mathsf{B}^1 Y_t + a_2 \\mathsf{B}^2 Y_t + a_3 \\mathsf{B}^3 Y_t \\\\\n& = \\cdots+a_{-1}Y_{t+1}+a_0Y_t+a_1Y_{t-1}+a_2Y_{t-2}+\\cdots \\; = \\; \\sum\\limits_{k=-\\infty}^{\\infty}a_kY_{t-k} \\\\\n% & =\\sum\\nolimits_{r=0}^3 a_r Y_{t-r} \\\\\n& =(\\boldsymbol{a}*\\boldsymbol{Y})_t,\\quad \\text{para } t\\in\\mathbb{Z}\n\\end{align*}\n\n"]},{"cell_type":"markdown","id":"19638522-3ad7-4576-aa8e-dd072590dd2e","metadata":{"slideshow":{"slide_type":"slide"}},"source":["## Ejemplos de procesos (débilmente) estacionarios\n\n"]},{"cell_type":"markdown","id":"14ac69b2-93a6-4359-8808-498f832b323d","metadata":{},"source":["### Proceso de ruido blanco\n\n"]},{"cell_type":"markdown","id":"ad290ced-7bb2-4c18-8301-d91be4424cce","metadata":{},"source":["Una secuencia $\\boldsymbol{U}=(U_t\\mid t\\in\\mathbb{Z})$ de variables\naleatorias **incorreladas** y tales que $$E(U_t)=0\\quad\\text{ y }\\quad\nVar(U_t)=E(U_t^2)=\\sigma^2$$ para $\\;t\\in\\mathbb{Z}\\;$ y\n$\\;0<\\sigma^2<\\infty\\;$ se llama *proceso de ruido blanco*.\n$\\quad\\boldsymbol{U}\\sim WN(0,\\sigma^2)$.\n\n"]},{"cell_type":"markdown","id":"f9f0d7e8-3fd9-4521-90fa-fbd4d5e84ee9","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["Al ser variables aleatorias incorreladas, su función de\nautocovarianzas es $$\\boldsymbol{\\gamma}(z)\\;=\\;\\sigma^2\nz^0\\;=\\;(\\ldots,0,0,\\sigma^2,0,0,\\ldots)$$\n\n-   Es el proceso estacionario (no trivial) más sencillo.\n-   **Este proceso es el pilar** sobre el que construiremos los procesos lineales.\n\n"]},{"cell_type":"markdown","id":"7f880c30-5ab4-49a6-aaa2-e387135e0de6","metadata":{"slideshow":{"slide_type":"skip"}},"source":["Algunas aclaraciones:\n\n1.  No es necesario que las variables sean independientes ni que tengan la misma distribución; pero sí se requiere que sean incorrelacionadas.\n2.  Si las variables son independientes (no solo incorrelacionadas), se llaman *ruido blanco estricto*.\n3.  Si el proceso $\\boldsymbol{U}$ de ruido blanco está formado por variables independientes e idénticamente distribuidas se denota con $\\;\\boldsymbol{U}\\sim IID(0,\\sigma^2)$; en tal caso el proceso es *estrictamente estacionario*.\n4.  Asumiendo que las variables siguen una distribución normal (*ruido blanco normal*):\n    -   La incorrelación implica independencia.\n    -   La normalidad asegura distribuciones marginales iguales.\n    -   Esto resulta en un proceso de *ruido blanco estricto* con variables normales.\n5.  La normalidad es una condición fuerte:\n    -   Existen procesos de ruido blanco estricto con variables de distribuciones no normales.\n    -   Ejemplo: Un proceso con variables uniformes independientes es ruido blanco estricto, pero no es ruido blanco normal\n6.  Un proceso de ruido blanco no requiere ser estacionario en sentido estricto, pero un proceso de ruido blanco normal lo es.\n\n"]},{"cell_type":"markdown","id":"3b53ca9c-b4f6-452b-952c-8e6bd9400bf8","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["### Procesos lineales\n\n"]},{"cell_type":"markdown","id":"b1b29518-7754-4442-a261-f480a0fcf6b6","metadata":{},"source":["Sea $\\boldsymbol{U}\\sim WN(0,\\sigma^2)$ y $\\boldsymbol{b}\\in\n\\ell^2$; una secuencia de <u>cuadrado sumable</u>\n$\\;\\sum\\limits_{j\\in\\mathbb{Z}}{b}_j^2<\\infty$.\n\nDenominamos *proceso lineal* al proceso estocástico\n$\\boldsymbol{X}=\\boldsymbol{b}*\\boldsymbol{U}$ cuyos elementos son $$X_t\n\\;=\\;(\\boldsymbol{b}*\\boldsymbol{U})_t\n\\;=\\;\\boldsymbol{b}(B)U_t \\;=\\;\\sum_{j=-\\infty}^\\infty {b}_j\nU_{t-j},\\quad\\text{con } t\\in\\mathbb{Z}.$$\n\nEste proceso es estacionario (véase la demo en los apuntes en <a href=\"https://mbujosab.github.io/Econometria-Aplicada/Lecciones-pdf/Lecc03.pdf#subsection.4.1\">pdf</a>)\n\n"]},{"cell_type":"markdown","id":"bcb03030-7a3b-4111-9a8a-7a384f275319","metadata":{"slideshow":{"slide_type":"notes"}},"source":["$\\boldsymbol{b}(B)$ se denomina *función de transferencia* del\nfiltro lineal que relaciona $X_t$ con $U_t$.\n\n"]},{"cell_type":"markdown","id":"88ce83c7-fe6d-4397-afbe-50365748d450","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["El proceso lineal es *\\`\\`causal''* si además $\\boldsymbol{b}$ es una\n<u>serie formal</u> (i.e., $cogrado(\\boldsymbol{b})\\geq{\\color{blue}{0}}$)\n$$X_t=\\sum_{j=0}^\\infty {b}_j U_{t-j};\\qquad t\\in\\mathbb{Z}$$ \n(pues cada $X_t$ es una suma de variables \"*del presente y/o el pasado*\").\n\n"]},{"cell_type":"markdown","id":"122037c4-42c3-4418-a0a9-f36e4da1f8d2","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["La clase de **procesos lineales causales** incluye muchas e importantes\nsubclases de procesos, algunas de las cuales son objeto principal de\nestudio de este curso.\n\n"]},{"cell_type":"markdown","id":"f0606672-b306-40a1-91e1-eacd6f8faacd","metadata":{"slideshow":{"slide_type":"slide"}},"source":["#### Media móvil infinita. MA($\\infty$)\n\n"]},{"cell_type":"markdown","id":"d0a799d8-7393-4997-96f6-143a9b3a0145","metadata":{},"source":["Sea $\\;\\boldsymbol{U}\\sim WN(0,\\sigma^2)\\;$ y sea $\\;\\boldsymbol{\\psi}\\in \\ell^2\\;$ una serie formal con <u>infinitos términos NO nulos</u> y ${\\color{#008000}{\\psi_{0}=1}}$; \nentonces el proceso estocástico $\\boldsymbol{\\psi}*\\boldsymbol{U}$, cuyos elementos son \n$$\nX_t\n\\;=\\;(\\boldsymbol{\\psi}*\\boldsymbol{U})_t\n\\;=\\;\\boldsymbol{\\psi}(B)U_t \\;=\\;\\sum_{j=0}^\\infty \\psi_j\nU_{t-j};\\qquad t\\in\\mathbb{Z}\n$$ \nse denomina proceso de *media móvil infinita* MA($\\infty$).\n\n"]},{"cell_type":"markdown","id":"ef0e1e4a-c8af-472f-a910-3629d8842c56","metadata":{"slideshow":{"slide_type":"slide"}},"source":["Algunas clases de procesos lineales causales poseen una representación parsimoniosa, pues basta un número finito de parámetros para describirlos completamente. \nPor ejemplo, cuando $\\boldsymbol{\\psi}$ tiene un número finito de términos no nulos&hellip;\n\n"]},{"cell_type":"markdown","id":"eb6b8b45-7a81-4c3a-be11-e791962616f3","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["#### Proceso de media móvil de orden $q$. MA($q$)\n\n"]},{"cell_type":"markdown","id":"78d5a585-be5c-42c0-883a-f83960f834ad","metadata":{},"source":["Sea $\\;\\boldsymbol{U}\\sim WN(0,\\sigma^2)\\;$ y sea\n$\\;\\boldsymbol{\\theta}\\;$ un <u>polinomio de grado $(q)$</u> con\n${\\color{#008000}{\\theta_{0}=1}}$; entonces el proceso estocástico\n$\\;\\boldsymbol{\\theta}*\\boldsymbol{U},\\;$ cuyos elementos son \n$$\n X_t\n \\;=\\;\n (\\boldsymbol{\\theta}*\\boldsymbol{U})_t\n \\;=\\;\n \\boldsymbol{\\theta}(B)U_t \n \\;=\\;\n \\sum_{j=0}^q\\theta_j U_{t-j};\n \\qquad t\\in\\mathbb{Z}\n$$\nse denomina proceso de *media móvil* MA($q$).\n\n"]},{"cell_type":"markdown","id":"2821c9c9-7a92-4b68-bc3d-7f73c713560d","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["Es decir, si $\\;\\boldsymbol{\\theta} \\;=\\; 1-\\theta_1z-\\cdots-\\theta_qz^q,\\;$ tenemos que\n$$\n X_t = U_t - \\theta_1 U_{t-1} - \\cdots - \\theta_q U_{t-q}.\n$$\n\n"]},{"cell_type":"markdown","id":"0c723e9a-9c08-47b6-b3cf-0b7c28b4ce67","metadata":{"slideshow":{"slide_type":"slide"}},"source":["Hay otros procesos lineales con representación parsimoniosa.\n\n"]},{"cell_type":"markdown","id":"3a7d4a31-d30f-4a7e-92a3-536f117913de","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["#### Proceso autorregresivo de orden $p$. AR($p$)\n\n"]},{"cell_type":"markdown","id":"52fa90af-1914-4224-b953-11595ef924d9","metadata":{},"source":["Sea $\\;\\boldsymbol{U}\\sim WN(0,\\sigma^2)\\;$, se denomina *proceso autorregresivo de orden $p$* a aquel proceso estocástico *estacionario* $\\;\\boldsymbol{X}\\;$ que es solución de la siguiente ecuación\n$$\n \\boldsymbol{\\phi}*\\boldsymbol{X}=\\boldsymbol{U}\n$$\ndonde $\\;\\boldsymbol{\\phi}\\;$ un <u>polinomio de grado $(p)$</u> con ${\\color{#008000}{\\phi_{0}=1}}$.\n\n"]},{"cell_type":"markdown","id":"ceafd6fa-a995-4093-a4bd-0bd36023b721","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["Por tanto, \n$$\n (\\boldsymbol{\\phi}*\\boldsymbol{X})_t\n \\;=\\;\n \\boldsymbol{\\phi}(\\mathsf{B})X_t\n \\;=\\;\n \\sum_{j=0}^p \\phi_j X_{t-j}\n \\;=\\;\n U_t.\n$$\n\n"]},{"cell_type":"markdown","id":"ca80dca9-4fa2-4c1e-b954-741760a35512","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["Si $\\;\\boldsymbol{\\phi}=1-\\phi_1z-\\cdots-\\phi_pz^p,\\;$ entonces $\\boldsymbol{X}=(X_t\\mid t\\in\\mathbb{Z})$ es solución de la ecuación en diferencias:\n$$\n X_t - \\phi_1 X_{t-1} - \\cdots -\\phi_p X_{t-p} = U_t.\n$$\n\n"]},{"cell_type":"markdown","id":"047ebb18-c234-42bf-9fad-661f02c93082","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["El problema con la anterior definición es que la ecuación $\\boldsymbol{\\phi}*\\boldsymbol{X}=\\boldsymbol{U}$ no tiene solución única (y en algunos casos ninguna solución es estacionaria).\nDespejemos $\\boldsymbol{X}$ para verlo.\n\nMultiplicando ambos lados de la ecuación por una inversa de $\\boldsymbol{\\phi}$ tenemos\n$$\n \\boldsymbol{X}=inversa(\\boldsymbol{\\phi})*\\boldsymbol{U}.\n$$\nY si denotamos la secuencia $inversa(\\boldsymbol{\\phi})$ con $\\boldsymbol{a}$ entonces\n$$\n X_t=\\boldsymbol{a}(\\mathsf{B})U_t=\\sum_{j\\in\\mathbb{Z}} a_j U_{t-j}.\n$$\n\n"]},{"cell_type":"markdown","id":"a29c3ae4-9efb-4c21-95f6-d6e7544d0137","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["Pero&hellip; ¿qué secuencia $\\boldsymbol{a}$ usamos como inversa de $\\boldsymbol{\\phi}$?\nRecuerde que hay infinitas y la mayoría no son sumables\n(si el polinomio $\\boldsymbol{\\phi}$ tiene raíces unitarias ninguna lo es).\n\n<div class=\"org-center\">\n<p>\nEn tal caso la expresión\n$\\;\\boldsymbol{a}(\\mathsf{B})U_t=\\sum\\limits_{j=-\\infty}^\\infty a_j U_{t-j}\\;$ \ncarece de sentido (pues la suma no converge).\n</p>\n</div>\n\n"]},{"cell_type":"markdown","id":"11d98b29-0084-411b-aa65-f25eb893bceb","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["**Requisitos** sobre el polinomio autorregresivo $\\boldsymbol{\\phi}:\\;$ para que el proceso AR exista y sea\n\n1.  <u>lineal y estacionario</u>, exigiremos que $\\boldsymbol{\\phi}$ <u>no tenga raíces de módulo 1</u>.\n    \n    Entonces existe una única inversa absolutamente sumable: $\\boldsymbol{\\phi}^{-1} \\in    \\ell^1\\subset\\ell^2$.\n    \n    La inversa $\\boldsymbol{\\phi}^{-1}$ corresponde a la única solución *estacionaria* de $\\boldsymbol{\\phi}*\\boldsymbol{X}=\\boldsymbol{U}$.\n    (Si $\\boldsymbol{\\phi}$ tuviera raíces de módulo 1 no existiría ni $\\boldsymbol{\\phi}^{-1}\\in\\ell^1$, ni solución estacionaria).\n    \n    $$X_t=\\boldsymbol{\\phi}^{-1}(\\mathsf{B})U_t=\\sum_{j=-\\infty}^\\infty a_j U_{t-j}$$\n\n2.  <u>causal</u>, exigiremos que las raíces de $\\boldsymbol{\\phi}$ sean mayores que 1 en valor absoluto (<u>raíces fuera del círculo unidad</u>):\n    $\\boldsymbol{\\phi}^{-1}=\\boldsymbol{\\phi}^{-\\triangleright}\\;$ (**serie formal** $\\in\\ell^1\\subset\\ell^2$).\n    \n    $$X_t=\\boldsymbol{\\phi}^{-1}(\\mathsf{B})U_t=\\sum_{j=0}^\\infty a_j U_{t-j};\\quad\\text{donde } \\boldsymbol{a}=\\boldsymbol{\\phi}^{-1}.$$\n\n"]},{"cell_type":"markdown","id":"8155308d-b3a3-4102-8b17-082a5b896d9e","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["(¡de nuevo un proceso lineal causal! En particular es un MA($\\infty$) pues ${\\color{#008000}{a_0=1}}$ por ser ${\\color{#008000}{\\phi_{0}=1}}$) \n\n"]},{"cell_type":"markdown","id":"e53a0670-3d7f-4d91-b35a-6096e2081cf0","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["El siguiente modelo lineal es una generalización de los dos anteriores.\n\n"]},{"cell_type":"markdown","id":"c4a6c17e-d955-4b3e-9f96-2e56d0f7dbd1","metadata":{"slideshow":{"slide_type":"slide"}},"source":["#### Proceso autorregresivo de media móvil. ARMA($p,q$)\n\n"]},{"cell_type":"markdown","id":"8f2111e7-c17e-4c7e-a286-8d5a57ab3ee3","metadata":{},"source":["Sea $\\;\\boldsymbol{U}\\sim WN(0,\\sigma^2)\\;$, se denomina *proceso autorregresivo de media móvil $(p,q)$* al proceso estocástico estacionario $\\;\\boldsymbol{X}\\;$ que es solución de la ecuación en diferencias:\n$$\n \\boldsymbol{\\phi}*\\boldsymbol{X}=\\boldsymbol{\\theta}*\\boldsymbol{U}\n$$\ndonde el polinomio *autorregresivo* $\\;\\boldsymbol{\\phi}\\;$ tiene grado $p$ con ${\\color{#008000}{\\phi_{0}=1}}$ y con todas sus raíces fuera del círculo unidad (*por los motivos anteriormente vistos*);\ny el polinomio *de media móvil* $\\;\\boldsymbol{\\theta}\\;$ es de grado $q$ con ${\\color{#008000}{\\theta_{0}=1}}$; \n\n$$\n \\text{es decir,}\\qquad\n \\boldsymbol{X}=\\frac{\\boldsymbol{\\theta}}{\\boldsymbol{\\phi}}*\\boldsymbol{U};\n \\qquad\\text{donde }\\;\n \\frac{\\boldsymbol{\\theta}}{\\boldsymbol{\\phi}}\\equiv\\boldsymbol{\\phi}^{-1}*\\boldsymbol{\\theta}\n$$\n\n"]},{"cell_type":"markdown","id":"7dc0a045-a542-4de2-8de8-592f65c2d140","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["Tanto $\\boldsymbol{\\phi}^{-1}$ como $\\boldsymbol{\\theta}$ son series formales absolutamente sumables. Dado que tanto $\\ell^1$ como las series formales son anillos: $\\;\\boldsymbol{\\phi}^{-1} * \\boldsymbol{\\theta}$ es otra una serie formal absolutamente sumable (y, por lo tanto, de cuadrado sumable). Consecuentemente, $\\boldsymbol{X}$ es, nuevamente, un proceso estocástico **lineal causal**.\n$$\n X_t\n \\;=\\;\n \\frac{\\boldsymbol{\\theta}}{\\boldsymbol{\\phi}}(\\mathsf{B})U_t\n \\;=\\;\n \\sum_{j=0}^\\infty a_j U_{t-j};\n \\quad\\text{donde } \\boldsymbol{a}=\\frac{\\boldsymbol{\\theta}}{\\boldsymbol{\\phi}}.\n$$\n\n"]},{"cell_type":"markdown","id":"53da7f96-1bc6-4ac3-9d4f-bedf843df838","metadata":{"slideshow":{"slide_type":"notes"}},"source":["#### Proceso autorregresivo de media móvil con media no nula\n\n"]},{"cell_type":"markdown","id":"7810666d-8029-41e0-a802-3ad7e06ff275","metadata":{"slideshow":{"slide_type":"notes"}},"source":["Consideremos un proceso $\\boldsymbol{Y}$ con media\ndistinta de cero, es decir, $$E(Y_t)=\\mu\\ne0$$ y definamos la\nsecuencia constante $\\boldsymbol{\\mu}=\\sum\\limits_{j\\in\\mathbb{Z}} \\mu\nz^j=(\\ldots,\\mu,\\mu,\\mu,\\ldots)$. \n\nDecimos que $\\boldsymbol{Y}$ es un proceso ARMA($p,q$) con media\ndistinta de cero si $\\boldsymbol{X}$ es ARMA($p,q$)\n$$\\boldsymbol{\\phi}*\\boldsymbol{X}=\\boldsymbol{\\theta}*\\boldsymbol{U}$$\ndonde $\\boldsymbol{X}=\\boldsymbol{Y}-\\boldsymbol{\\mu}$ es\nevidentemente un proceso de media cero.  Por tanto\n\n\\begin{align*}\n\\boldsymbol{\\phi}*(\\boldsymbol{Y}-\\boldsymbol{\\mu})=&\\boldsymbol{\\theta}*\\boldsymbol{U}\\\\\n\\boldsymbol{\\phi}*\\boldsymbol{Y}-\\boldsymbol{\\phi}*\\boldsymbol{\\mu}=&\\boldsymbol{\\theta}*\\boldsymbol{U}\\\\\n\\boldsymbol{\\phi}*\\boldsymbol{Y}=&\\boldsymbol{\\phi}*\\boldsymbol{\\mu}+ \\boldsymbol{\\theta}*\\boldsymbol{U}\\\\\n\\end{align*}\n\nEs decir, si $\\boldsymbol{\\phi}(\\mathsf{B})$ es\n$\\;1-\\phi_1\\mathsf{B}-\\phi_2\\mathsf{B}^2-\\cdots-\\phi_p\\mathsf{B}^p,\\;$\nentonces $$\\boldsymbol{\\phi}(B){Y_t}=c+\\boldsymbol{\\theta}(B){U_t}$$\ndonde $$\\;c=(1-\\phi_1-\\phi_2-\\cdots-\\phi_p)\\mu\\;$$ y donde\n$\\;\\mu=E(Y_t)$, es un proceso autorregresivo de media móvil\nARMA($p,q$) *con media no nula*.\n\n"]},{"cell_type":"markdown","id":"2793bc56-1ae2-4f06-aa72-f4cbf0d90fdb","metadata":{"slideshow":{"slide_type":"skip"}},"source":["## Primeros momentos de procesos lineales causales\n\n"]},{"cell_type":"markdown","id":"b148de40-a3f0-4792-9303-6cda4c52c9ac","metadata":{"slideshow":{"slide_type":"slide"}},"source":["### Esperanza y autocovarianzas de un proceso lineal causal\n\n"]},{"cell_type":"markdown","id":"35a856f3-1b52-46ac-9efc-7484d83cc766","metadata":{},"source":["Sea $\\;\\boldsymbol{X}=\\boldsymbol{\\psi}*\\boldsymbol{U},\\;$ donde $\\boldsymbol{\\psi}$ es una serie formal de cuadrado sumable y donde $\\;\\boldsymbol{U}\\sim WN(0,\\sigma^2).\\quad$ \nRecordando que la convolución es una operación lineal: \n$$\n E(\\boldsymbol{X}) =E(\\boldsymbol{\\psi}*\\boldsymbol{U})\n =\\boldsymbol{\\psi}*E(\\boldsymbol{U})\n =\\boldsymbol{\\psi}*\\boldsymbol{0}=\\boldsymbol{0}.\n$$\nAsí, la covarianza de orden $k$ para cada $X_t$ es \n(demo en el [pdf](https://mbujosab.github.io/Econometria-Aplicada/Lecciones-pdf/Lecc03.pdf#subsection.4.2)):\n$$\n \\gamma_{_{k,t}}\n \\;=\\;\n E\\Big[\\big(\\boldsymbol{\\psi}(\\mathsf{B})X_t\\big)\\cdot \\big(\\boldsymbol{\\psi}(\\mathsf{B}) X_{t-k}\\big)\\Big] \n % \\;=\\;\n % \\sigma^2\\sum\\nolimits_{j\\in\\mathbb{Z}}\\psi_{j+k}\\psi_j\n \\;=\\;\n \\sigma^2 \\big(\\boldsymbol{\\psi}(z)*\\boldsymbol{\\psi}(z^{-1})\\big)_k\n$$\nque no depende de $t$ ($\\boldsymbol{X}$ es estacionario), es decir, $\\gamma_{_{k,t}}=\\gamma_{k}$.\nY, por tanto\n\n\\begin{equation}\n \\label{eqAutoCovarianzaProcesoLineal}\n \\boldsymbol{\\gamma}=\\sigma^2\\boldsymbol{\\psi}(z)*\\boldsymbol{\\psi}(z^{-1}).\n\\end{equation}\n\ncon grado igual al grado de $\\boldsymbol{\\psi}$ y cogrado igual a menos el grado de $\\boldsymbol{\\psi}$.\n\n"]},{"cell_type":"markdown","id":"e31f037d-d7e6-46e2-a9dc-f6e15435f5a2","metadata":{"slideshow":{"slide_type":"slide"}},"source":["### Covarianza cruzada entre dos procesos lineales causales\n\n"]},{"cell_type":"markdown","id":"155ced1c-7676-4ba3-a98a-f3a8ae907c11","metadata":{},"source":["Sean $\\;\\boldsymbol{W}=\\boldsymbol{\\theta}*\\boldsymbol{U}\\quad$ e\n$\\quad\\boldsymbol{Y}=\\boldsymbol{\\psi}*\\boldsymbol{U},\\quad$ donde\n$\\boldsymbol{\\theta}$ y $\\boldsymbol{\\psi}$ son series formales de\ncuadrado sumable y donde $\\;\\boldsymbol{U}\\sim\nWN(0,\\sigma^2)$.\n\nRepitiendo los mismos pasos que en el caso de la autocovarianza,\nllegamos a que la <u>función de covarianzas cruzadas</u> es la secuencia\n\n\\begin{equation}\n \\label{eqCovarianzaCruzadaProcesosLineales}\n \\boldsymbol{\\gamma_{_{\\boldsymbol{W},\\boldsymbol{Y}}}} =\n \\sigma^2 \\boldsymbol{\\theta}(z)*\\boldsymbol{\\psi}(z^{-1})\n\\end{equation}\n\ncon grado igual al grado de $\\boldsymbol{\\theta}$ y cogrado igual a menos\nel grado de $\\boldsymbol{\\psi}$.\n\n"]},{"cell_type":"markdown","id":"848f13d0-be88-4620-9a9d-d32d82ac25d7","metadata":{"slideshow":{"slide_type":"skip"}},"source":["Un proceso de ruido blanco $\\boldsymbol{U}\\sim WN(0,\\sigma^2)$ es un\nproceso *débilmente estacionario* (o estacionario de segundo orden)\ntal que: $$E(U_t)=0;\\qquad t\\in\\mathbb{Z}$$ y $$\\boldsymbol{\\gamma} =\n(\\ldots,\\,0,\\,0,\\,{\\color{blue}{\\sigma^2}},\\,0,\\,0,\\ldots)=\\sigma^2\nz^0;$$ es decir, $\\;\\gamma_0=\\sigma^2\\;$ y $\\;\\gamma_k=0\\;$ para todo\n$k\\ne0$.\n\nConsideremos el proceso estocástico: $\\quad\\boldsymbol{X}=(X_t \\mid\nt=0,\\pm1,\\pm2,\\ldots).\\quad$ Lo podemos denotar con una función\ngeneratriz (como hicimos con las secuencias) $$\\boldsymbol{X} \\quad =\n\\quad \\sum_{t=-\\infty}^\\infty X_t z^t \\quad\\equiv\\quad\n\\boldsymbol{X}(z)$$ Recuerde que esto no es una suma; es una secuencia\nde variables aleatorias $$\\sum_{t=-\\infty}^\\infty X_t z^t = (\\ldots,\\\nX_{-2},\\ X_{-1},\\ X_{0},\\ X_{1},\\ X_{2},\\ldots)$$\n\n"]}],"metadata":{"org":null,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":5}